from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA, ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
import json
import PyPDF2
import streamlit as st
import os
import shutil
from datetime import datetime
from langchain.document_loaders import DirectoryLoader
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import pickle
from langchain.chains import LLMChain
from langchain.prompts import ChatPromptTemplate

os.environ["PYDANTIC_V2_FORCE"] = "1"

load_dotenv()
st.set_page_config("My RAG Chatbot", "üí¨", layout="wide")

# API Keys
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# Using OpenAI embeddings
embeddings = OpenAIEmbeddings(
    openai_api_key=OPENAI_API_KEY,
    model="text-embedding-3-small"
)

# For OpenAI's GPT-4 llm
llm = ChatOpenAI(
    temperature=0,
    openai_api_key=OPENAI_API_KEY,
    model="gpt-4"
)

# Initialize session state for chat history if it doesn't exist
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = datetime.now().strftime("%Y%m%d_%H%M%S")
if "chat_mode" not in st.session_state:
    st.session_state.chat_mode = "kb"  # Default to knowledge base mode

# For reading PDFs and returning text string
def read_pdf(files):
    file_content=""
    for file in files:
        # Create a PDF file reader object
        pdf_reader = PyPDF2.PdfReader(file)
        # Get the total number of pages in the PDF
        num_pages = len(pdf_reader.pages)
        # Iterate through each page and extract text
        for page_num in range(num_pages):
            # Get the page object
            page = pdf_reader.pages[page_num]
            file_content += page.extract_text()
    return file_content


def migrate_knowledge_bases():
    """Migrate existing knowledge bases to the new structure"""
    path = "db"
    if not os.path.exists(path):
        os.makedirs(path)
        st.sidebar.info("Created new db directory")
        return
        
    # Get all existing indices
    existing_indices = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]
    
    migrated_count = 0
    for index_name in existing_indices:
        index_path = os.path.join(path, index_name)
        original_docs_path = os.path.join(index_path, "original_docs")
        
        # Check if this index already has the new structure
        if not os.path.exists(original_docs_path):
            os.makedirs(original_docs_path)
            
            # Create embedding info file if it doesn't exist
            embedding_info_path = os.path.join(index_path, "embedding_info.json")
            if not os.path.exists(embedding_info_path):
                embedding_info = {
                    "model": "text-embedding-3-small",  # Assuming this was the model used
                    "migrated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "note": "This is a migrated knowledge base. Original documents may be missing."
                }
                with open(embedding_info_path, "w") as f:
                    json.dump(embedding_info, f)
            
            migrated_count += 1
    
    if migrated_count > 0:
        st.sidebar.success(f"Migrated {migrated_count} knowledge bases to the new structure")


def rebuild_index(index_name):
    """Rebuild the index using current embedding model"""
    try:
        # Get the original documents path
        docs_path = os.path.join("db", index_name, "original_docs")
        if not os.path.exists(docs_path) or len(os.listdir(docs_path)) == 0:
            st.error(f"No original documents found for {index_name}")
            st.info("This knowledge base was created before the migration. You'll need to re-upload the documents.")
            return False
        
        # Load documents
        loader = DirectoryLoader(docs_path, glob="**/*.pdf", loader_cls=PyPDFLoader)
        documents = loader.load()
        
        if not documents:
            st.error("No valid documents found in the knowledge base")
            return False
        
        # Split documents
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        texts = text_splitter.split_documents(documents)
        
        # Create new vector store
        kb_path = os.path.join("db", index_name)
        new_db = FAISS.from_documents(texts, embeddings)
        
        # Save embedding info
        embedding_info = {
            "model": "text-embedding-3-small",
            "dimensions": len(embeddings.embed_query("test")),
            "rebuilt_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        with open(os.path.join(kb_path, "embedding_info.json"), "w") as f:
            json.dump(embedding_info, f)
            
        # Save the new index
        new_db.save_local(kb_path)
        
        return True
    except Exception as e:
        st.error(f"Error rebuilding index: {e}")
        return False


def can_rebuild_kb(index_name):
    """Check if a knowledge base has original documents and can be rebuilt"""
    original_docs_path = os.path.join("db", index_name, "original_docs")
    return os.path.exists(original_docs_path) and len(os.listdir(original_docs_path)) > 0


def debug_embedding_dimensions():
    """Debug function to check embedding dimensions"""
    # Check current embedding dimensions
    test_text = "This is a test sentence."
    current_embedding = embeddings.embed_query(test_text)
    st.sidebar.write(f"Current embedding dimensions: {len(current_embedding)}")
    
    # Try to check FAISS index dimensions
    if st.session_state.book_docsearch and hasattr(st.session_state.book_docsearch, 'index'):
        try:
            st.sidebar.write(f"FAISS index dimensions: {st.session_state.book_docsearch.index.d}")
        except:
            st.sidebar.write("Could not determine FAISS index dimensions")

# Save chat history to file
def save_chat_history():
    if not os.path.exists("chat_histories"):
        os.makedirs("chat_histories")
    
    history_path = os.path.join("chat_histories", f"chat_{st.session_state.conversation_id}.pkl")
    
    # Convert conversation_chatbot format to chat_history format if needed
    if st.session_state.conversation_chatbot and not st.session_state.chat_history:
        for item in st.session_state.conversation_chatbot:
            st.session_state.chat_history.append({"role": "user", "content": item[0]})
            st.session_state.chat_history.append({"role": "assistant", "content": item[1]})
    
    with open(history_path, "wb") as f:
        pickle.dump(st.session_state.chat_history, f)
    
    return history_path

#-----------------------------------------------------------#
#------------------------üí¨ CHATBOT -----------------------#
#----------------------------------------------------------#
def chatbot():
    if st.session_state.chat_mode == "kb":
        st.subheader("Ask questions from the PDFs")
    else:
        st.subheader("General Conversation Mode")
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    # Display chat messages from history
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Knowledge Base Mode
    if st.session_state.chat_mode == "kb":
        # Check if it is empty
        if st.session_state.book_docsearch:   
            prompt = st.chat_input("Ask a question about your documents")
            
            if prompt:
                # Add user message to chat history
                st.session_state.chat_history.append({"role": "user", "content": prompt})
                
                # Display user message
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                with st.spinner("Getting Answer..."):
                    try:
                        # Create memory from existing chat history
                        memory = ConversationBufferMemory(
                            memory_key="chat_history",
                            return_messages=True
                        )
                        
                        # Add previous messages to memory
                        for message in st.session_state.chat_history:
                            if message["role"] == "user":
                                memory.chat_memory.add_user_message(message["content"])
                            elif message["role"] == "assistant":
                                memory.chat_memory.add_ai_message(message["content"])
                        
                        # No of chunks the search should retrieve from the db
                        chunks_to_retrieve = 5
                        retriever = st.session_state.book_docsearch.as_retriever(
                            search_type="similarity", 
                            search_kwargs={"k": chunks_to_retrieve}
                        )

                        # Use ConversationalRetrievalChain for context-aware responses
                        qa = ConversationalRetrievalChain.from_llm(
                            llm=llm,
                            retriever=retriever,
                            memory=memory,
                            verbose=True
                        )
                        
                        response = qa.invoke({"question": prompt})
                        answer = response["answer"]
                        
                        # Display assistant response
                        with st.chat_message("assistant"):
                            st.markdown(answer)
                        
                        # Add assistant response to chat history
                        st.session_state.chat_history.append({"role": "assistant", "content": answer})
                        
                        # Also update the old conversation_chatbot format for backward compatibility
                        metadata = {"kb_used": st.session_state.selected_option}
                        st.session_state.conversation_chatbot.append((prompt, answer, metadata))
                        
                        # Showing chunks with score
                        try:
                            doc_score = st.session_state.book_docsearch.similarity_search_with_score(prompt, k=chunks_to_retrieve)
                            with st.expander("View source documents"):
                                st.write(doc_score)
                        except Exception as e:
                            st.error(f"Error retrieving source documents: {e}")
                            st.info("Try rebuilding the knowledge base from the sidebar.")
                        
                        # Display which KB was used
                        st.caption(f"*Knowledge base used: {st.session_state.selected_option}*")
                        
                    except Exception as e:
                        st.error(f"Error processing your query: {e}")
                        print(e)
                        if "assert d == self.d" in str(e):
                            st.warning("Dimension mismatch detected. Please rebuild the knowledge base from the sidebar.")
        else:
            st.warning("Please select a knowledge base from the sidebar")
    
    # General Conversation Mode (without knowledge base)
    else:
        prompt = st.chat_input("Chat with the AI assistant")
        
        if prompt:
            # Add user message to chat history
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            
            # Display user message
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.spinner("Thinking..."):
                try:
                    # Create a conversation history to pass to the model
                    messages = []
                    for message in st.session_state.chat_history:
                        if message["role"] == "user":
                            messages.append({"role": "user", "content": message["content"]})
                        elif message["role"] == "assistant":
                            messages.append({"role": "assistant", "content": message["content"]})
                    
                    # Get response from the model
                    response = llm.invoke(messages)
                    answer = response.content
                    
                    # Display assistant response
                    with st.chat_message("assistant"):
                        st.markdown(answer)
                    
                    # Add assistant response to chat history
                    st.session_state.chat_history.append({"role": "assistant", "content": answer})
                    
                    # Also update the old conversation_chatbot format for backward compatibility
                    metadata = {"mode": "general_conversation"}
                    st.session_state.conversation_chatbot.append((prompt, answer, metadata))
                    
                    # Display which mode was used
                    st.caption("*General conversation mode (no knowledge base)*")
                    
                except Exception as e:
                    st.error(f"Error processing your query: {e}")
                    print(e)

            
# For initialization of session variables
def initial(flag=False):
    path="db"
    if 'existing_indices' not in st.session_state or flag:
        if os.path.exists(path):
            st.session_state.existing_indices = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]
        else:
            st.session_state.existing_indices = []
            
    if ('selected_option' not in st.session_state) or flag:
        try:
            st.session_state.selected_option = st.session_state.existing_indices[0]
        except:
            st.session_state.selected_option = None
    
    if 'conversation_chatbot' not in st.session_state:
        st.session_state.conversation_chatbot = []
    if 'book_docsearch' not in st.session_state:
        st.session_state.book_docsearch = None

def load_kb():
    # Load the selected index from local storage
    if st.session_state.selected_option:
        try:
            kb_path = os.path.join("db", st.session_state.selected_option)
            
            # Check if this knowledge base has been migrated
            embedding_info_path = os.path.join(kb_path, "embedding_info.json")
            if os.path.exists(embedding_info_path):
                with open(embedding_info_path, "r") as f:
                    embedding_info = json.load(f)
                    
                # Check if the embedding model matches
                if embedding_info.get("model") != "text-embedding-3-small":
                    st.sidebar.warning(f"‚ö†Ô∏è This knowledge base was created with {embedding_info.get('model')} but you're using text-embedding-3-small.")
            
            st.session_state.book_docsearch = FAISS.load_local(
                kb_path, 
                embeddings, 
                allow_dangerous_deserialization=True
            )
            st.sidebar.success(f"Loaded knowledge base: {st.session_state.selected_option}")
        except Exception as e:
            error_msg = str(e)
            st.sidebar.error(f"Error loading knowledge base: {error_msg}")
            
            # Check if it's a dimension mismatch error
            if "assert d == self.d" in error_msg:
                st.sidebar.warning("‚ö†Ô∏è This appears to be a dimension mismatch error. The knowledge base was created with a different embedding model.")
                
                # Check if we have original documents to rebuild
                original_docs_path = os.path.join("db", st.session_state.selected_option, "original_docs")
                if os.path.exists(original_docs_path) and len(os.listdir(original_docs_path)) > 0:
                    st.sidebar.info("Use the 'Rebuild Knowledge Base' button to fix this issue.")
                else:
                    st.sidebar.info("This knowledge base needs to be recreated. Please upload the documents again.")
            
            st.session_state.book_docsearch = None
    else:
        st.session_state.book_docsearch = None

def main():
    initial(True)
    
    # Run migration on startup
    migrate_knowledge_bases()
    
    # Sidebar for knowledge base selection
    with st.sidebar:
        st.title("Chat Mode Selection")
        st.markdown("---")
        
        # Chat mode selection
        chat_mode = st.radio(
            "Select chat mode:",
            ["Knowledge Base Chat", "General Conversation"],
            index=0 if st.session_state.chat_mode == "kb" else 1,
            key="chat_mode_selection"
        )
        
        # Update session state based on selection
        if chat_mode == "Knowledge Base Chat" and st.session_state.chat_mode != "kb":
            st.session_state.chat_mode = "kb"
            st.rerun()
        elif chat_mode == "General Conversation" and st.session_state.chat_mode != "general":
            st.session_state.chat_mode = "general"
            st.rerun()
        
        # Debug button
        if st.button("Debug Embedding Dimensions"):
            debug_embedding_dimensions()
        
        # Only show knowledge base selection if in KB mode
        if st.session_state.chat_mode == "kb":
            st.markdown("---")
            st.title("Knowledge Base Selection")
            
            if not st.session_state.existing_indices:
                st.warning("‚ö†Ô∏è No knowledge bases found. Please add a new index.")
                st.page_link("pages/Knowledge_Bases.py", label="Upload Files", icon="‚¨ÜÔ∏è")
            else:
                file_list = []
                for index in st.session_state.existing_indices:
                    try:
                        with open(f"db/{index}/desc.json", "r") as openfile:
                            description = json.load(openfile)
                            file_list.append(",".join(description["file_names"]))
                    except:
                        file_list.append("No description available")
                
                st.write("### Select a knowledge base")
                selected_index = st.radio(
                    "Available knowledge bases:", 
                    st.session_state.existing_indices, 
                    captions=file_list, 
                    index=0 if st.session_state.selected_option in st.session_state.existing_indices else 0,
                    key="kb_selection"
                )
                
                if selected_index != st.session_state.selected_option:
                    st.session_state.selected_option = selected_index
                    load_kb()
                    st.info("Knowledge base changed - conversation history is maintained")
                
                st.markdown("---")
                st.write("### Knowledge Base Info")
                if st.session_state.selected_option:
                    try:
                        with open(f"db/{st.session_state.selected_option}/desc.json", "r") as openfile:
                            description = json.load(openfile)
                            st.write(f"**Files:** {', '.join(description['file_names'])}")
                            if 'description' in description:
                                st.write(f"**Description:** {description['description']}")
                            if 'created_at' in description:
                                st.write(f"**Created:** {description['created_at']}")
                    except:
                        st.write("No additional information available.")
                
                # Maintenance options for KB mode
                st.markdown("---")
                st.write("### Maintenance Options")
                
                col1, col2 = st.columns(2)
                
                # Add a rebuild button if the knowledge base has original documents
                with col1:
                    if st.session_state.selected_option and can_rebuild_kb(st.session_state.selected_option):
                        if st.button("Rebuild Knowledge Base"):
                            with st.spinner("Rebuilding index with current embedding model..."):
                                if rebuild_index(st.session_state.selected_option):
                                    st.success("Knowledge base rebuilt successfully!")
                                    # Reload the knowledge base
                                    load_kb()
                                    st.rerun()
                                else:
                                    st.error("Failed to rebuild knowledge base.")
                    else:
                        st.button("Rebuild Knowledge Base", disabled=True)
                        if st.session_state.selected_option:
                            st.info("No original documents available for rebuilding")
                
                # Button to refresh the knowledge base list
                with col2:
                    if st.button("Refresh Knowledge Bases"):
                        initial(True)
                        load_kb()
                
                # Link to upload page
                st.markdown("---")
                st.page_link("pages/Knowledge_Bases.py", label="Upload New Files", icon="‚¨ÜÔ∏è")
        
        # Chat history options (available in both modes)
        st.markdown("---")
        st.write("### Chat History Options")
        
        col1, col2 = st.columns(2)
        
        # Clear chat history button
        with col1:
            if st.button("Clear Chat History"):
                st.session_state.chat_history = []
                st.session_state.conversation_chatbot = []
                st.session_state.conversation_id = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.rerun()
        
        # Save chat history button
        with col2:
            if st.button("Save Chat History") and (st.session_state.chat_history or st.session_state.conversation_chatbot):
                saved_path = save_chat_history()
                st.success(f"Chat history saved!")
        
        # Link to chat history page if it exists
        if os.path.exists("pages/Chat_History.py"):
            st.page_link("pages/Chat_History.py", label="View Saved Chat Histories", icon="üìú")
    
    # Main content area
    st.title("üí∞ Mutual Fund Chatbot")
    
    # Show different content based on chat mode
    if st.session_state.chat_mode == "kb":
        if st.session_state.selected_option:
            st.info(f"Currently using knowledge base: **{st.session_state.selected_option}**")
            chatbot()
        else:
            st.warning("‚ö†Ô∏è No knowledge base selected. Please select one from the sidebar.")
    else:
        st.info("You are in general conversation mode. Ask any questions without using a knowledge base.")
        chatbot()
            
if __name__ == "__main__":
    main()